<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>LoopModels: poly::CostModeling::LoopTreeCostFn Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">LoopModels
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>poly</b></li><li class="navelem"><b>CostModeling</b></li><li class="navelem"><a class="el" href="classpoly_1_1CostModeling_1_1LoopTreeCostFn.html">LoopTreeCostFn</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="classpoly_1_1CostModeling_1_1LoopTreeCostFn-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">poly::CostModeling::LoopTreeCostFn Class Reference</div>  </div>
</div><!--header-->
<div class="contents">

<p><code>#include &lt;<a class="el" href="CostFunction_8hpp_source.html">CostFunction.hpp</a>&gt;</code></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a6fdfbdfa21e5fdacdf97c9a08623b609"><td class="memItemLeft" align="right" valign="top"><a id="a6fdfbdfa21e5fdacdf97c9a08623b609"></a>
constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>operator()</b> (alloc::Arena&lt;&gt; alloc, const AbstractVector auto &amp;x) const</td></tr>
<tr class="separator:a6fdfbdfa21e5fdacdf97c9a08623b609"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a40564f0b519fe6d7c28d9a87d03598e4"><td class="memItemLeft" align="right" valign="top"><a id="a40564f0b519fe6d7c28d9a87d03598e4"></a>
void&#160;</td><td class="memItemRight" valign="bottom"><b>init</b> (<a class="el" href="structpoly_1_1CostModeling_1_1LoopDepSatisfaction.html">LoopDepSatisfaction</a> deps, <a class="el" href="classpoly_1_1IR_1_1Loop.html">IR::Loop</a> *root, unsigned maxl2VF, llvm::LLVMContext &amp;C, const llvm::TargetTransformInfo &amp;TTI)</td></tr>
<tr class="separator:a40564f0b519fe6d7c28d9a87d03598e4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8d069a20d459b131044dbf39833b50df"><td class="memItemLeft" align="right" valign="top"><a id="a8d069a20d459b131044dbf39833b50df"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>LoopTreeCostFn</b> (<a class="el" href="structpoly_1_1CostModeling_1_1LoopDepSatisfaction.html">LoopDepSatisfaction</a> deps, <a class="el" href="classpoly_1_1IR_1_1Loop.html">IR::Loop</a> *root, unsigned maxVF, llvm::LLVMContext &amp;C, const llvm::TargetTransformInfo &amp;TTI)</td></tr>
<tr class="separator:a8d069a20d459b131044dbf39833b50df"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>memcost = I*J*(Ui*Uj*C_{Al} + Uj*C_{yl}) / (Ui*Uj) + I*(C_{xl}*Ui + C_{xs}*Ui) / Ui cthroughput = I*J*(Ui*Uj*C_{t,fma}) / (Ui*Uj) + I*(Ui*C_{t,add}*(Uj-1)) / Ui clatency = I*J*C_{l,fma}/smin(Ui*Uj, C_{l,fma}/C_{t,fma}) + I*C_{l,add}*log2(Uj)</p>
<p>Here, we define a cost fn that can be optimized to produce</p>
<p>vectorization and unrolling factors. We assemble all addrs into a vector, sorted by depth first traversal order of the loop tree, e.g. A(0) --&gt; B(1) --&gt; C(2) --&gt; D(3) -&gt; E(5) --&gt; F(6) -&gt; G(4) -&gt; H(7) --&gt; I(8) --&gt; J(9) Focusing only on memory addresses initially... The cost of a particular read/write can be looked up from LLVM as a function of scalar/gather/scatter/broadcast/contiguous. Then this can be adjusted by the product of all unroll factors of loops it depends on, divided by the product of all unroll factors of all containing loops. To optimize, we can branch and bound. Unrolling factors lead to a natural relaxation that plays well, but less so for binary variables like which loop is vectorized. Additionally, patterns such as replacing gather/scatters with shuffle sequences need special handling, that restricts the branch and bound to powers of 2. To be able to build such a cost model, we need to estimate the number of live variables as a result of unroll factors, in order to impose constraints.</p>
<p>We use soft constraints for register pressuring, representing the store/reload pair of a spill.</p>
<p>Furthermore, we also need to consider the possibility of dependency chains. Consider, for example </p><div class="fragment"><div class="line"><span class="keywordflow">for</span> (ptrdiff_t i = 0; i &lt; I; ++i){</div>
<div class="line">  eltype_t&lt;A&gt; xi = x[i];</div>
<div class="line">  <span class="keywordflow">for</span> (ptrdiff_t j = 0; j &lt; J; ++j)</div>
<div class="line">    xi += A[i][j] * y[j];</div>
<div class="line">  x[i] = xi;</div>
<div class="line">}</div>
</div><!-- fragment --><p> The <code>j</code> loop itself has a dependency chain. Two options for addressing this:</p><ol type="1">
<li>unrolling <code>j</code>, cloning the accumulation registers, and reducing at the end.</li>
<li>unrolling the <code>i</code> loop. The second option is better, but may not be possible, e.g. if there is no <code>i</code> loop or it carries some dependency. Thus, we want our model to unroll <code>i</code> when legal, and unroll <code>j</code> otherwise. Assuming a throughput of 2 fma/cycle and a latency of 4 cycles, an estimate of the cost as a function of I, J, Ui, and Uj is (ignoring vectorization): 4*I*J/min(Ui*Uj, 2*4) + 4*I*log2(Uj) The first term is latency per fma (because of the dependency chain) * the number of iterations, divided by however many unrolling allows us to have inflight. The second term is for the reduction of the cloned <code>Uj</code> accumulators. Each step in the reduction has a latency of 4 cycles, and we need to do <code>log2(Uj)</code> steps.</li>
</ol>
<p>Note, <code>y-softplus(l*(y-x))/l</code> is a good smooth minimum function, monotonic in <code>x</code> and differentiable everywhere. <code>l</code> controls sharpness. Likewise, <code>y+softplus(l*(x-y))/l</code> for <code>max</code>.</p>
<p>Thus, a cost function for the above gemv could be something like memcost = I*J*(Ui*Uj*C_{Al} + Uj*C_{yl}) / (Ui*Uj) + I*(C_{xl}*Ui + C_{xs}*Ui) / Ui cthroughput = I*J*(Ui*Uj*C_{t,fma}) / (Ui*Uj) + I*(Ui*C_{t,add}*(Uj-1)) / Ui clatency = I*J*C_{l,fma}/smin(Ui*Uj, C_{l,fma}/C_{t,fma}) + I*C_{l,add}*log2(Uj) cost = memcost + smax(cthroughput, clatency) or, if the it is easier to solve: cost = memcost + cthroughput + clatency</p>
<p>We may initially want to add a small cost for loop increment and cmp/branch, to encourage unrolling more generally, plus a cost for unrolling to discourse any excess unrolling when it doesn't provide meaningful benefits (representing the general cost of code size/ filling uop cache &ndash; we definitely want loops to fit in the uop cache of any CPU sporting one!!! ).</p>
<p>Note that if we had </p><div class="fragment"><div class="line"><span class="keywordflow">for</span> (ptrdiff_t i = 0; i &lt; I; ++i){</div>
<div class="line">  eltype_t&lt;A&gt; yi = y[i];</div>
<div class="line">  <span class="keywordflow">for</span> (ptrdiff_t j = 0; j &lt; J; ++j)</div>
<div class="line">    x[j] += A[i][j] * yi;</div>
<div class="line">}</div>
</div><!-- fragment --><p> then unrolling the <code>i</code> loop doesn't increase OOO (Out Of Order execution), but we can assume that as successive <code>j</code> iterations are independent/do not have a dependency chain, this isn't an issue. That is, we only consider reductions across the inner-most loop as requiring cloning of accumulators.</p>
<p>On throughput modeling, LLVM seems to generally give a recip throughput of 1 for pipelined instructions, regardless of number of ports. This is actually what we want, as this allows RTs to be additive (e.g., we may have a fma that is able to run on 2 ports (e.g. p0 or p5) and a permute that can only execute on one (e.g. p5); when mixing these instructions, they have the same effective cost &ndash; they use a port &ndash; and the more limited port choices of one isn't a problem so long as others can use what remains. For our purposes, it isn't worth getting too fancy here. It is worth noting that the baseline model presented here <a href="https://arxiv.org/pdf/2107.14210.pdf">https://arxiv.org/pdf/2107.14210.pdf</a> performed respectively well when compared to vastly more sophisticated tools; for example, it performed similarly well as llvm-mca on most tested architectures! The baseline model used above for loops was max(1, (n-1)/i, m_r/m, m_w/w) where n - the number of instructions in the benchmark (-1 because of assumption that the cmp and branch are macro-fused, meaning the last two instructions count as 1) m_r - number of memory reads m_w - number of memory writes i - the issue width, e.g. 4 for Intel Skylake CPUs. m - number of reads the CPU can do per cycle (2 for all in the article) w - number of writes the CPU can do per cycle (e.g. 2 for Ice Lake and newer, 1 for older) Unfortunately, we cannot get the CPU-specific information (<code>i</code>,<code>m</code>,or<code>w</code>) from LLVM. However, these are largely a matter of scale, and are generally correlated. E.g., Intel's Alderlake's values would be 6, 3, and 2, vs the older Skylake's 4, 2, and 1. While not all the ratios are equal (<code>w</code>'s is 2 instead of 1.5), it is unlikely that many optimization decisions are going to be made differently between them. A possible exception is that we may wish to unroll more for CPUs with more out of order execution abilities. <code>getMaxInterleaveFactor</code> is an indicator of whether the pipeline might be very narrow.</p>
<p>Given <code>x[a*i + b*j]</code>, where neither <code>i</code> or <code>j</code> are vectorized (and <code>a</code> and <code>b</code> are compile time constants), we use: (a_g*U_i + b_g*U_j - a_g*b_g) / (U_i*U_j) = a_g/U_j + b_g/U_i - a_g*b_g / (U_i*U_j) = 1 - (1 - a_g/U_j ) * (1 - b_g/U_i) as the cost, where <code>a_g = abs(a/gcd(a,b))</code> and <code>b_g = abs(b/gcd(a,b))</code>.</p>
<p>For more, we generalize this pattern = 1 - \prod_{d}^{D}\left(1 - \frac{coef_{g,d}*U_d}{\prod_{i}^{D}U_i}\right)</p>
<p>In the <code>D=3</code> case, this expands to 1 - (1 - a_g/(U_j*U_k))(1 - b_g/(U_i*U_k))(1 - c_g/(U_i*U_j)) = 1 - (1 - c_g/(U_i*U_j))* (1 - a_g/(U_j*U_k) - b_g/(U_i*U_k)) + a_g*b_g/(U_i*U_j*U_k^2)) = a_g/(U_j*U_k) + b_g/(U_i*U_k)) + c_g/(U_i*U_j) - a_g*b_g/(U_i*U_j*U_k^2))</p><ul>
<li>a_g*c_g/(U_i*U_j^2*U_k) - b_g*c_g/(U_i^2*U_j*U_k))</li>
<li>a_g*b_g*c_g/(U_i^2*U_j^2*U_k^2))</li>
</ul>
<p>TODO: check the degree of correctness... I kind of just made something up that looks sort of right.</p>
<p>For register consumption, we</p><ol type="1">
<li>Determine an ordering of unroll factors for each inner most loop.</li>
<li>Define a registers used as a function of these unroll factors.</li>
</ol>
<p>Loads from inner unrolls that don't depend on any outer-unrolls must have lifetimes spanning all outer-unrolls, if they're re-used by an op depending on that outer. Our heuristic for ordering unrolls is based on the twin observations:</p><ol type="1">
<li>Inner unrolls are likely to consume more registers for longer.</li>
<li>More ops with overlapping lifetimes dependent on one particular loop require more registers.</li>
</ol>
<p>As the ordering of unrolls influences register pressure, we sort them first by register cost per unroll (placing those with the highest register cost outside), and then by memory op cost within these categories, placing the highest costs innermost (higher memory cost means lower unroll relative to the lower cost, so that we get more reuse on the higher cost operations; lower unroll means we place inside, reducing the cost of these unrolls).</p>
<p>So, how do we define register cost per unroll in an unroll-order independent manner, so that we can use this for determining the order? </p><div class="fragment"><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> m=0; m&lt;M; ++m){</div>
<div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> n=0; n&lt;N; ++n){</div>
<div class="line">    <span class="keyword">auto</span> Cmn = C[m,n];</div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k=0; k&lt;K; ++k)</div>
<div class="line">      Cmn += A[m,k]*B[k,n];</div>
<div class="line">    C[m,n] = Cmn;</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><p> In this example, we have 4 ops in the inner loop A[m,k] &mdash;&gt;*--&gt; (Cmn +=) B[k,n] -/</p>
<p>Register Costs: Amk_rc = U_m * U_k // live until use Bkn_rc = U_k * U_n // live until use Cmn_rc = U_m * U_n // live until end of loop Memory Op Costs, m-vectorized (assuming column-major): Amk_rc = L_c * U_m * U_k Bkn_rc = L_b * U_k * U_n Cmn_rc = 0 * U_m * U_n L_c &gt; L_b, so A-contiguous load should be interior to B-broadcast load.</p>
<p>As the cost function is evaluated many times, we try and move as much work to the setup as possible. Loop cost is thus divided into some structured components, and much of the interpreting work hoisted to a step defining a parameterization. Ideally, we would avoid repeating this work for different vectorization decisions. However, vectorization decisions may impact unroll ordering decisions.</p>
<p>/// </p>
</div><hr/>The documentation for this class was generated from the following file:<ul>
<li>include/Optimize/<a class="el" href="CostFunction_8hpp_source.html">CostFunction.hpp</a></li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
