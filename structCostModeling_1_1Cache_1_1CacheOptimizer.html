<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.9.1"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>LoopModels: CostModeling::Cache::CacheOptimizer Struct Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">LoopModels
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.9.1 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search','.html');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>CostModeling</b></li><li class="navelem"><b>Cache</b></li><li class="navelem"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer.html">CacheOptimizer</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#nested-classes">Classes</a> &#124;
<a href="#pub-types">Public Types</a> &#124;
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-static-methods">Static Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="#pub-static-attribs">Static Public Attributes</a> &#124;
<a href="structCostModeling_1_1Cache_1_1CacheOptimizer-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">CostModeling::Cache::CacheOptimizer Struct Reference</div>  </div>
</div><!--header-->
<div class="contents">
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1InnerMostConstraint.html">InnerMostConstraint</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1InnerPerm.html">InnerPerm</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Loop.html">Loop</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1PopBack.html">PopBack</a></td></tr>
<tr class="separator:"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-types"></a>
Public Types</h2></td></tr>
<tr class="memitem:a4617e362067a93f3a4986e036083a876"><td class="memItemLeft" align="right" valign="top"><a id="a4617e362067a93f3a4986e036083a876"></a>
using&#160;</td><td class="memItemRight" valign="bottom"><b>Cache</b> = <a class="el" href="structtarget_1_1MachineCore_1_1Cache.html">target::MachineCore::Cache</a></td></tr>
<tr class="separator:a4617e362067a93f3a4986e036083a876"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a5423a823eba52c76ea42895a6d1abbe3"><td class="memItemLeft" align="right" valign="top"><a id="a5423a823eba52c76ea42895a6d1abbe3"></a>
constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>setCacheFactor</b> (ptrdiff_t depth0, int cache_factor) -&gt; double</td></tr>
<tr class="separator:a5423a823eba52c76ea42895a6d1abbe3"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a100d75bffda530d56923677a00fc8973"><td class="memItemLeft" align="right" valign="top"><a id="a100d75bffda530d56923677a00fc8973"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>pushLoop</b> (<a class="el" href="structCostModeling_1_1LoopSummary.html">LoopSummary</a> loopinfo, int reg_factor, double phi_cost) -&gt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1PopBack.html">PopBack</a></td></tr>
<tr class="separator:a100d75bffda530d56923677a00fc8973"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8109ec193ed0a9cedae031d97f899146"><td class="memItemLeft" align="right" valign="top"><a id="a8109ec193ed0a9cedae031d97f899146"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>innerConstraint</b> (<a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> &amp;countdeps, ptrdiff_t chain_len) -&gt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1InnerMostConstraint.html">InnerMostConstraint</a></td></tr>
<tr class="separator:a8109ec193ed0a9cedae031d97f899146"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ad521a4a3719807937f071802a1fbf8"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer.html#a9ad521a4a3719807937f071802a1fbf8">fitGrid</a> (const <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> &amp;deps, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1InnerMostConstraint.html">InnerMostConstraint</a> imc) -&gt; DensePtrMatrix&lt; int &gt;</td></tr>
<tr class="separator:a9ad521a4a3719807937f071802a1fbf8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a080b9bac825d2eec5cf8d48be3ea8caa"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer.html#a080b9bac825d2eec5cf8d48be3ea8caa">optInnerMost</a> (<a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *deps_ptr, ptrdiff_t chain_len) -&gt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a></td></tr>
<tr class="separator:a080b9bac825d2eec5cf8d48be3ea8caa"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af90d9611f1249107947e32c84f685286"><td class="memItemLeft" align="right" valign="top"><a id="af90d9611f1249107947e32c84f685286"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>remainingPhiSpillCost</b> () -&gt; double</td></tr>
<tr class="separator:af90d9611f1249107947e32c84f685286"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a350caee26a5105809455ba7039ad8842"><td class="memItemLeft" align="right" valign="top"><a id="a350caee26a5105809455ba7039ad8842"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>cacheOptBisect</b> (<a class="el" href="structCostModeling_1_1LoopSummaries.html">LoopSummaries</a> ls, double *phi_costs, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *ds, ptrdiff_t chain_len, ptrdiff_t nsubloops, std::array&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a>, NB &gt; bounds, <a class="el" href="structCostModeling_1_1LoopTransform.html">LoopTransform</a> *best_trf) -&gt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a></td></tr>
<tr class="separator:a350caee26a5105809455ba7039ad8842"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:abaca88bd0b918d00acff01dc3d95b891"><td class="memItemLeft" align="right" valign="top"><a id="abaca88bd0b918d00acff01dc3d95b891"></a>
constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>complete</b> (const std::array&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a>, NB &gt; &amp;bounds) -&gt; bool</td></tr>
<tr class="separator:abaca88bd0b918d00acff01dc3d95b891"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7d7b3373feb815f5c929e11597087ced"><td class="memItemLeft" align="right" valign="top"><a id="a7d7b3373feb815f5c929e11597087ced"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>bisectSplit</b> (<a class="el" href="structCostModeling_1_1LoopSummaries.html">LoopSummaries</a> ls, double *phi_costs, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *ds, ptrdiff_t chain_len, ptrdiff_t nsubloops, <a class="el" href="structCostModeling_1_1LoopTransform.html">LoopTransform</a> *best_trf, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a> best, bool upper, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a> current, std::array&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a>, NB &gt; &amp;bounds) -&gt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a></td></tr>
<tr class="separator:a7d7b3373feb815f5c929e11597087ced"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a16b68c519ff840da075631b086c37298"><td class="memItemLeft" align="right" valign="top"><a id="a16b68c519ff840da075631b086c37298"></a>
constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>depth1</b> () const -&gt; ptrdiff_t</td></tr>
<tr class="separator:a16b68c519ff840da075631b086c37298"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab395aafed04b1d33e9ff62e559bc46d6"><td class="memItemLeft" align="right" valign="top"><a id="ab395aafed04b1d33e9ff62e559bc46d6"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>cacheOptCost</b> (<a class="el" href="structCostModeling_1_1LoopSummaries.html">LoopSummaries</a> ls, double *phi_costs, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *ds, ptrdiff_t chain_len, ptrdiff_t nsubloops, int cache_factor) -&gt; Tuple&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a>, <a class="el" href="structCostModeling_1_1LoopSummaries.html">LoopSummaries</a>, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *, int &gt;</td></tr>
<tr class="separator:ab395aafed04b1d33e9ff62e559bc46d6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a57703d955fc2a2a876d5a4f350b40721"><td class="memItemLeft" align="right" valign="top"><a id="a57703d955fc2a2a876d5a4f350b40721"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>cacheOptCost</b> (<a class="el" href="structCostModeling_1_1LoopSummaries.html">LoopSummaries</a> ls, double *phi_costs, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *ds, ptrdiff_t chain_len, ptrdiff_t nsubloops, int cache_factor, double bestc, <a class="el" href="structCostModeling_1_1LoopTransform.html">LoopTransform</a> *best_trf) -&gt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a></td></tr>
<tr class="separator:a57703d955fc2a2a876d5a4f350b40721"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0911928e5e8ddc90c26d58dddc8819c9"><td class="memItemLeft" align="right" valign="top"><a id="a0911928e5e8ddc90c26d58dddc8819c9"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>cacheOptEntry</b> (<a class="el" href="structCostModeling_1_1LoopSummary.html">LoopSummary</a> loopinfo, int reg_factor, <a class="el" href="structCostModeling_1_1LoopSummaries.html">LoopSummaries</a> ls, double *phi_costs, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *ds, ptrdiff_t chain_len) -&gt; Tuple&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a>, <a class="el" href="structCostModeling_1_1LoopSummaries.html">LoopSummaries</a>, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *, int &gt;</td></tr>
<tr class="separator:a0911928e5e8ddc90c26d58dddc8819c9"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aca746f551f27850d54e092a445b9897f"><td class="memItemLeft" align="right" valign="top"><a id="aca746f551f27850d54e092a445b9897f"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>cacheOpt</b> (<a class="el" href="structCostModeling_1_1LoopSummary.html">LoopSummary</a> loopinfo, <a class="el" href="structCostModeling_1_1LoopTransform.html">LoopTransform</a> trf, <a class="el" href="structCostModeling_1_1LoopSummaries.html">LoopSummaries</a> ls, double *phi_costs, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *ds) -&gt; Pair&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a>, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> * &gt;</td></tr>
<tr class="separator:aca746f551f27850d54e092a445b9897f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac4087f46d0dd4274821133f5893c0e0d"><td class="memItemLeft" align="right" valign="top"><a id="ac4087f46d0dd4274821133f5893c0e0d"></a>
auto&#160;</td><td class="memItemRight" valign="bottom"><b>cacheOpt</b> (<a class="el" href="structCostModeling_1_1LoopSummaries.html">LoopSummaries</a> ls, double *phi_costs, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *ds) -&gt; Pair&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a>, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> * &gt;</td></tr>
<tr class="separator:ac4087f46d0dd4274821133f5893c0e0d"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-methods"></a>
Static Public Member Functions</h2></td></tr>
<tr class="memitem:aa2000026c26850a83436b47c3878af71"><td class="memItemLeft" align="right" valign="top"><a id="aa2000026c26850a83436b47c3878af71"></a>
static auto&#160;</td><td class="memItemRight" valign="bottom"><b>checkCacheDep</b> (uint32_t ac, uint32_t bc) -&gt; bool</td></tr>
<tr class="separator:aa2000026c26850a83436b47c3878af71"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a262108c303cebcad7d025f8156f1b8d7"><td class="memItemLeft" align="right" valign="top">static void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer.html#a262108c303cebcad7d025f8156f1b8d7">fillTileSizes</a> (MutStridedVector&lt; int &gt; tile_size, const TinyVector&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Loop.html">Loop</a>, 15 &gt; &amp;unrolls, uint16_t deps, uint32_t cpy_mask, ptrdiff_t depth0, int size)</td></tr>
<tr class="separator:a262108c303cebcad7d025f8156f1b8d7"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9dc132ec0ec903fba009f6e3c8a28811"><td class="memItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer.html#a9dc132ec0ec903fba009f6e3c8a28811">rotateDepMask</a> (uint32_t deps, uint32_t reg, uint32_t cache) -&gt; uint32_t</td></tr>
<tr class="separator:a9dc132ec0ec903fba009f6e3c8a28811"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ab8833924c612cf9e18e04867063efdb0"><td class="memItemLeft" align="right" valign="top"><a id="ab8833924c612cf9e18e04867063efdb0"></a>
static auto&#160;</td><td class="memItemRight" valign="bottom"><b>getFreq</b> (const containers::TinyVector&lt; double, 29 &gt; &amp;freqs, ptrdiff_t depth0, uint32_t dr, ptrdiff_t nct, ptrdiff_t inner_idx, ptrdiff_t chain_len) -&gt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1InnerMostConstraint_1_1Cost.html">InnerMostConstraint::Cost</a></td></tr>
<tr class="separator:ab8833924c612cf9e18e04867063efdb0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a98cbf405755bcb31ffeb6bf4a97a7089"><td class="memItemLeft" align="right" valign="top"><a id="a98cbf405755bcb31ffeb6bf4a97a7089"></a>
static auto&#160;</td><td class="memItemRight" valign="bottom"><b>phiSpillCost</b> (const <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Loop.html">Loop</a> &amp;l) -&gt; double</td></tr>
<tr class="separator:a98cbf405755bcb31ffeb6bf4a97a7089"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a74dcfd8c37b5494a354b17f9e2c8187f"><td class="memItemLeft" align="right" valign="top"><a id="a74dcfd8c37b5494a354b17f9e2c8187f"></a>
static constexpr auto&#160;</td><td class="memItemRight" valign="bottom"><b>splitUpUpper</b> (std::array&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a>, NB &gt; a, <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a> x) -&gt; std::array&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a>, NB &gt;</td></tr>
<tr class="separator:a74dcfd8c37b5494a354b17f9e2c8187f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6971844b213cd81d14b659632d540db4"><td class="memTemplParams" colspan="2"><a id="a6971844b213cd81d14b659632d540db4"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a6971844b213cd81d14b659632d540db4"><td class="memTemplItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memTemplItemRight" valign="bottom"><b>splitLowUpper</b> (std::array&lt; T, NB &gt; a, T x) -&gt; std::array&lt; T, NB &gt;</td></tr>
<tr class="separator:a6971844b213cd81d14b659632d540db4"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ae7f88e9e1352362d14b6e08c481a755a"><td class="memTemplParams" colspan="2"><a id="ae7f88e9e1352362d14b6e08c481a755a"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:ae7f88e9e1352362d14b6e08c481a755a"><td class="memTemplItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memTemplItemRight" valign="bottom"><b>splitUpLower</b> (std::array&lt; T, NB &gt; a, T x) -&gt; std::array&lt; T, NB &gt;</td></tr>
<tr class="separator:ae7f88e9e1352362d14b6e08c481a755a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0b7535cec134a4f198fe9bccab9ba80f"><td class="memTemplParams" colspan="2"><a id="a0b7535cec134a4f198fe9bccab9ba80f"></a>
template&lt;typename T &gt; </td></tr>
<tr class="memitem:a0b7535cec134a4f198fe9bccab9ba80f"><td class="memTemplItemLeft" align="right" valign="top">static constexpr auto&#160;</td><td class="memTemplItemRight" valign="bottom"><b>splitLowLower</b> (std::array&lt; T, NB &gt; a, T x) -&gt; std::array&lt; T, NB &gt;</td></tr>
<tr class="separator:a0b7535cec134a4f198fe9bccab9ba80f"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:aad33cb5794566196b79f67cfb5e623e8"><td class="memItemLeft" align="right" valign="top"><a id="aad33cb5794566196b79f67cfb5e623e8"></a>
TinyVector&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Loop.html">Loop</a>, 15 &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>unrolls_</b></td></tr>
<tr class="separator:aad33cb5794566196b79f67cfb5e623e8"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac5684184c2cc35f72de563e41d29c294"><td class="memItemLeft" align="right" valign="top"><a id="ac5684184c2cc35f72de563e41d29c294"></a>
containers::TinyVector&lt; <a class="el" href="structtarget_1_1MachineCore_1_1Cache.html">Cache</a>, 4 &gt;&#160;</td><td class="memItemRight" valign="bottom"><b>caches_</b></td></tr>
<tr class="separator:ac5684184c2cc35f72de563e41d29c294"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af279d9a743c1462fd3884b1c33e7552c"><td class="memItemLeft" align="right" valign="top"><a id="af279d9a743c1462fd3884b1c33e7552c"></a>
int&#160;</td><td class="memItemRight" valign="bottom"><b>cachelinebits_</b></td></tr>
<tr class="separator:af279d9a743c1462fd3884b1c33e7552c"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6a613bab9def6be5c9764abe7f4872e7"><td class="memItemLeft" align="right" valign="top"><a id="a6a613bab9def6be5c9764abe7f4872e7"></a>
alloc::Arena&#160;</td><td class="memItemRight" valign="bottom"><b>alloc_</b></td></tr>
<tr class="separator:a6a613bab9def6be5c9764abe7f4872e7"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-static-attribs"></a>
Static Public Attributes</h2></td></tr>
<tr class="memitem:a6208edffd10195abc20ef66553123324"><td class="memItemLeft" align="right" valign="top"><a id="a6208edffd10195abc20ef66553123324"></a>
static constexpr ptrdiff_t&#160;</td><td class="memItemRight" valign="bottom"><b>NumBounds</b> = 3</td></tr>
<tr class="separator:a6208edffd10195abc20ef66553123324"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a10fbaaa14120931440ef346e3b5de31b"><td class="memItemLeft" align="right" valign="top"><a id="a10fbaaa14120931440ef346e3b5de31b"></a>
static constexpr ptrdiff_t&#160;</td><td class="memItemRight" valign="bottom"><b>NB</b> = (2 * NumBounds) + 1</td></tr>
<tr class="separator:a10fbaaa14120931440ef346e3b5de31b"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Our approach is to consider different strategies from the inside-out. We evaluated conditioned on micro-kernel parameters that determine L1-&gt;register costs. Each strategy adds different possible constraints and costs. If the number of constraints equals the number of variables, we solve, and use these to continuesolving as we work our way out. Once we reach the end, we need to optimize the cost function w/ respect to free variables if there are any. We must return all the final costs.</p>
<p>We may also need to recompute some L1 load bandwidth costs? Or, how to handle packing dramatically reducing costs? TODO: add packing optimization at micro-kernel opt-level</p>
<p>Consider this example: </p><pre class="fragment"> for (int n = 0; n &lt; N; ++n){
   for (int m = 0; m &lt; M; ++m){
     Cmn = 0f0;
     for (int k = 0; k &lt; K; ++k)
       Cmn += A[m,k]*B[k,n];
     C[m,n] = f(Cmn + x[m]);
   }
   for (int i = 0; i &lt; I; ++i){
     Ein = 0f0;
     for (int j = 0; j &lt; M; ++j)
       Ein += D[i,j]*C[j,n];
     E[i,n] = g(Ein + y[i]);
   }
 }
</pre><p> we have n_r, m_r, k_r, i_r, j_r let n_f, m_f, k_f, i_f, j_f be integer-valued cache-factors, so that n_c = n_f*n_r, m_c = m_f*m_r, k_c = k_f*k_r, i_c = i_f*i_r, j_c = j_f*j_r</p>
<p>L_i = S_iW_i, where <code>L_i</code> is the <code>i</code>th cache size, <code>W_i</code> is the number of ways of the <code>i</code>th cache, and <code>S_i</code> is the critical stride, i.e. number of sets*cacheline size. We leave reduction loops as the inner-most. We look directly outside, we have</p>
<p>C: m_r*n_r x: m_r A: m_r*k_c B: k_c*n_r Options:</p><ol type="1">
<li>fit m_r*k_c in L1 across iters, loop over n_r in n_c</li>
<li>fit k_c*n_r in L1 across iters, loop over m_r in m_c</li>
<li>don't fit, instead stream through L1</li>
</ol>
<p>Expanding on the constraints and costs of each: L1 use: m_r*k_c + k_c*n_r + m_r*n_r + m_r We need to avoid overloading any cache-ways, thus options 1 and 2 require: m_r*k_c &lt;= S_1*u_A k_c*n_r &lt;= S_1*u_B m_r*n_r &lt;= S_1*u_C // u_C = 1 m_r &lt;= S_1*u_X // u_X = 1 u_A + u_B + 1 &lt;= W_1 <code>u_A</code> and <code>u_B</code> are positive integers, equal to the number of ways used. Any heuristic for combining <code>u_C</code> and <code>u_X</code>? Probably that their sum is still below <code>1</code>. The entirety of <code>m_r*k_c</code> and <code>k_c*n_r</code> are touched on each iteration, thus depending on the order, either can be evicted and replaced. We're assuming/hoping that the <code>m_r*n_r</code> and <code>m_r</code> are scattered enough to avoid evicting. Options <code>1</code> and <code>2</code> require the three contraints, option <code>3</code> does not. Instead, option <code>3</code> has the constraint: m_r*k_c &gt;= S_1*u_A k_c*n_r &gt;= S_1*u_B m_r*n_r &gt;= S_1*u_C // u_C = 1 m_r &gt;= S_1*u_X // u_X = 1 u_A + u_B + 1 &gt;= W_1 That is, we've flipped the inequalities. Option 3, which produces greater bandwidth costs, only makes sense when we get to violate these. The above constraint is unbounded, and thus not yet solveable; we'd just get <code>k_c = K</code>.</p>
<p>L2-&gt;L1 bandwidth cost for each of the three is:</p><ol type="1">
<li>(M/m_r)(N/n_c)(K/k_c)*(m_r*k_c + m_r + (n_c/n_r)*(k_c*n_r + 2*m_r*n_r)) = M*(N/n_c)*K + M*(N/n_c)*(K/k_c) + (M/m_r)*N*K + 2*M*N*(K/k_c) A x B C</li>
<li>(M/m_c)(N/n_r)(K/k_c)*(k_c*n_r + (m_c/m_r)*(m_r*k_c + m_r + m_r*n_r)) = M*(N/n_r)*K + M*(N/n_r)*(K/k_c) + (M/m_c)*N*K + 2*M*N*(K/k_c) A x B C</li>
<li>(M/m_r)(N/n_r)(K/k_c)*(m_r*k_c + m_r + k_c*n_r + 2*m_r*n_r) = M*(N/n_r)*K + M*(N/n_r)*(K/k_c) + (M/m_r)*N*K + 2*M*N*(K/k_c) A x B C NOTE: On many CPUs, the L2-&gt;L1 bandwidth is sufficiently high, and the L1 size sufficiently small, that option 3. is best. But our approach will probably be to carry all options through to the outermost, unless we can prove an option is guarnateed to be dominated. In case of options 1 and 2, we have 3 constraints and 3 unknowns. Using an integer-relaxation, using equality: u_A = m_r*k_c/S_1 u_B = k_c*n_r/S_1 m_r*k_c/S_1 + k_c*n_r/S_1 + 1 = W_1 k_c*(m_r + n_r)/S_1 = W_1 - 1 k_c = S_1*(W_1 - 1)/(m_r + n_r) This is an integer-relaxation-value. Should perhaps floor <code>u_A</code> and <code>u_B</code> above, and then take k_c = floor(min(S_1*u_A/m_r k_c, S_1*u_B/n_r)) In the "violate" case, we don't get any constraints, but have the larger L2-&gt;L1 bandwidth cost as a result.</li>
</ol>
<p>Then for the next loop and L3-&gt;L2 bandwidth, we have... Option 1a: fit k_c*n_c in L2 across iters, loop over m_r in m_c Option 1b: don't fit, instead stream through l2 Option 2a: fit m_c*k_c + m_c in L2 across iters, loop over n_r in n_c Option 2b: don't fit, instead stream through l2 Option 3a: fit k_c*n_c in L2 across iters, loop over m_r in m_c, n_r in n_c Option 3b: fit m_c*k_c + m_c in L2 across iters, loop over n_r in n_c, m_r in m_c Option 3c: don't fit, instead stream through l2</p>
<p>Fitting in cache is now more difficult, because we touch the entirety of those arrays we discard, but only part of those that we keep. That means, for the order for n_r in n_c, m_r in m_c where we keep <code>m_c*k_c + m_c</code>, we iterate over that <code>m_c</code> in pieces. The <code>m_c*n_r</code> is also iterated in pieces, thus the new loads will be able to evict the old. The <code>k_c*n_r</code>, however, is iterated in its entirety for each <code>n_r</code>, making it more recently used than all but the last <code>m_f</code> when it comes time to evict. Thus, we keep the space for two of these, so that the older one will be least recently used and evicted. We have:</p>
<p>m_c*k_c = S_2*u_A2 k_c*n_r = S_2*u_B2 m_c*n_r = S_2*u_C2 m_c = S_2*u_X2 // u_X2 is probably 1 W_2 = u_A2 + 2*u_B2 + u_C2 + u_X2 unknowns: m_c, u_A2, u_B2, u_C2, u_X2 maybe known: k_c, if we're option 2a Thus, in option 2a, we can solve for <code>m_c</code>. In option 3b, we will eventually need to solve. Either way, the L3-&gt;L2 bandwidth cost assuming we do fit is: (M/m_c)*(K/k_c)*(N/n_c)[ m_c*k_c + m_c + (n_c/n_r) * (k_c*n_r + m_c*n_r) ] M*K*(N/n_c) + M*(K/k_c)*(N/n_c) + (M/m_c)*K*N + M*(K/k_c)*N</p>
<p>The <code>don't fit</code> options defer. If neither fit, we get the previous level's bandwidth cost. If the inner (<code>m_c</code>) tile fits, we'd get: (M/m_c)*(K/k_c)*(N/n_c)[ (n_c/n_r) * (m_c*k_c + m_c + k_c*n_r + m_c*n_r) ] M*K*(N/n_c) + M*(K/k_c)*(N/n_c) + (M/m_c)*K*N + M*(K/k_c)*N</p>
<p>If, in the end, we've defered all the way, we don't do any packing. This is likely of course when there are no reuse opportunities, or the loop sizes are known at compile time to be too small enough for cache tiling and packing to be profitable.</p>
<p>Note that we cannot frame this as a linear program in general, as we can have products of many arguments. It thus isn't necessarilly quadratic either. Branch-and-bound is probably still useful.</p>
<p>Implementation ideas/thoughts: We care about the history of unrolling. But we need a tree When we have multiple branches/subloops, we want to merge their impacts...</p>
<p>Particular arrays that are indexed define a history... Lets try and start a stupid-way</p>
<p>Note that cache tiles can be placed in different orders outside of the microkernel loop, just like unroll orders can vary.</p>
<p>Our tiling is also layered based on number of cache-layers?</p>
<p>The first idea to try, I think, as described above, is to build up a big set of possible strategies...</p>
<p>We want to be able to use the constraints to simplify as many of the loops as we can. Taking the earlier example, let's assume we are using the following orders: clang-format off </p><pre class="fragment">for (int n_c_b = 0; n_c_b &lt; N; n_c_b += n_c){     // held in L3
  for (int k_c_b = 0; k_c_b &lt; K; k_c_b += k_c){   // held in L2
    for (int m_c_b = 0; m_c_b &lt; M; m_c_b += m_c){ // held in L2
      for (int n_r_b = n_c_b; n_r_b &lt; n_c+n_c_b; n_r_b += n_r){ // L2
        for (int m_r_b = m_c_b; m_r_b &lt; m_c+m_c_b; m_r_b += m_r){
          Cmn = C[m_r_b+_(0,m_r),n_r_b+_(0,n_r)];
          if (k_c_b == 0) Cmn &lt;&lt; 0;
          for (int k_r_b = k_c_b; k_r_b &lt; k_c+k_c_b; k_r_b += k_r){
            Cmn += A[m_r_b+_(0,m_r),k_r_b+_(0,k_r)] *
                   B[k_r_b+_(0,k_r),n_r_b+_(0,n_r)];
          } // k_r_b
          Cmn += x[m_r_b+_(0,m_r)];
          C[m_r_b+_(0,m_r),n_r_b+_(0,n_r)] &lt;&lt; f(Cmn);
        } // m_r_b
      } // n_r_b
    } // m_c_b
  } // k_c_b
  for (int j_c_b = 0; j_c_b &lt; J; j_c_b += j_c){   // held in L2
    for (int i_c_b = 0; i_c_b &lt; I; i_c_b += i_c){ // held in L2
      for (int n_r_b = n_c_b; n_r_b &lt; n_c+n_c_b; n_r_b += n_r){ // L2
        for (int i_r_b = i_c_b; i_r_b &lt; i_c+i_c_b; i_r_b += i_r){
          Ein = E[i_r_b+_(0,i_r),n_r_b+_(0,n_r)];
          if (j_c_b == 0) Ein &lt;&lt; 0;
          for (int j_r_b = j_c_b; j_r_b &lt; j_c+j_c_b; j_r_b += j_r){
            Ein += D[i_r_b+_(0,i_r),j_r_b+_(0,j_r)] *
                   C[j_r_b+_(0,j_r),n_r_b+_(0,n_r)];
          } // j_r_b
          Ein += y[i_r_b+_(0,i_r)];
          E[i_r_b+_(0,i_r),n_r_b+_(0,n_r)] &lt;&lt; g(Ein);
        } // j_c_b
      } // n_r_b
    } // i_c_b
  } // j_c_b
} // n_c_b
</pre><p> Above, "held in" means that given slice is held in memory</p>
<p>Additionally, let's assume we are</p><ol type="1">
<li>streaming L2-&gt;L1 (nothing is held in L1)</li>
<li>holding <code>m_c</code>, <code>k_c</code>, <code>i_c</code>, and <code>j_c</code> in L2</li>
<li>holding <code>n_c</code> in L3.</li>
</ol>
<p>Now, we have the following: Having the <code>n_c_b</code> loop fused is only likely to be helpful if <code>(k_c &gt;= K) &amp;&amp; (m_c &gt;= M)</code> Q: should we really keep <code>n_r</code> constant across sub-loops? A: Long term, may want to lift that restriction... Q: What sort of legality check do we need? A: We'll restrict cache-tiling to be within the inner-most reorderable-band.</p>
<p>Let all of these be integer-valued: <code>x_r</code> be reg tile size <code>x_c</code> be reg tile size <code>x_f = x_c/x_r</code> be reg tile size</p>
<p>We have the following costs: L1 -&gt; L0 = 2*M*N*(K/k_c - 1) + 2*I*N*(J/j_c - 1) C E</p><ul>
<li>2*M*K + 2*N*K + 2*I*J + 2*N*J pA pB pD pC Most of the <code>L1 -&gt; L0</code> costs are accounted for in the microkernel cost calculation, but we have additional loads and stores related to the phi-nodes of the reduction loops for each time we must repeat them. The <code>p*</code> costs are the pack + unpack costs of the packed arrays. These are added for every level of the memory hierarchy. L2 -&gt; L1 = M*(N/n_r)*K + M*(N/n_r)*(K/k_c) + (M/m_r)*N*K + 2*M*N*(K/k_c) A x B C</li>
<li>I*(N/n_r)*J + I*(N/n_r)*(J/j_c) + (I/i_r)*N*J + 2*I*N*(J/j_c) D y C E</li>
<li>2*M*K + 2*N*K + 2*I*J + 2*N*J pA pB pD pC Held: none, order n_c, k_c, m_c, [n_r, m_r, k_r] Held: none, order n_c, j_c, i_c, [n_r, i_r, j_r] Because we don't hold in L1, we'd have all the tile factors as denominators. However, the order of <code>k_r_b</code> and <code>j_r_b</code> being inner-most let us hoist those that don't depend on <code>k</code> or <code>j</code> out, and thus we get the improved <code>k_c</code> and <code>j_c</code> denominators.</li>
</ul>
<p>The exact costs are, for all-reg (<code>k_r</code> and <code>j_r</code> are inner-most): A: (M/m_c)(N/n_c)(K/k_c) * (m_c/m_r)(n_c/n_r)(k_c/k_r) * m_r*k_r x: (M/m_c)(N/n_c)(K/k_c) * (m_c/m_r)(n_c/n_r) * m_r B: (M/m_c)(N/n_c)(K/k_c) * (m_c/m_r)(n_c/n_r)(k_c/k_r) * k_r*n_r</p>
<p>C: (N/n_c)*(n_c/n_r)*n_r*[2(M/m_c)(K/k_c)*(m_c/m_r)*m_r + (I/i_c)(J/j_c)*(i_c/i_r)(j_c/j_r)*j_r] D: (I/i_c)(N/n_c)(J/j_c) * (i_c/i_r)(n_c/n_r)(j_c/j_r) * i_r*j_r y: (I/i_c)(N/n_c)(J/j_c) * (i_c/i_r)(n_c/n_r) * i_r E: 2*(I/i_c)(N/n_c)(J/j_c) * (i_c/i_r)(n_c/n_r) * i_r*n_r</p>
<p>If we did hold <code>k_c</code> and <code>j_c</code> in L1, with <code>m_r</code> and <code>i_r</code> as inner-most regs, we'd instead have: A: (M/m_c)(N/n_c)(K/k_c) * (m_c/m_r)(n_c/n_r) * m_r*k_c x: (M/m_c)(N/n_c)(K/k_c) * (m_c/m_r)(n_c/n_r) * m_r B: (M/m_c)(N/n_c)(K/k_c) * (n_c/n_r) * k_c*n_r</p>
<p>C: (N/n_c)*(n_c/n_r)*n_r*[2(M/m_c)(K/k_c)*(m_c/m_r)*m_r + (I/i_c)(J/j_c)*(j_c/j_r)*j_r] D: (I/i_c)(N/n_c)(J/j_c) * (i_c/i_r)(n_c/n_r) * i_r*j_c y: (I/i_c)(N/n_c)(J/j_c) * (i_c/i_r)(n_c/n_r) * i_r E: 2*(I/i_c)(N/n_c)(J/j_c) * (i_c/i_r)(n_c/n_r) * i_r*n_r</p>
<p>The chief difficulties above are</p><ol type="1">
<li><code>k</code> is the inner-most <code>reg</code> loop, hence, things that don't depend on it drop the cache-factor component of the cost.</li>
<li>That we mave multipliers <code>2*</code>; we need to store frequencies with deps.</li>
</ol>
<p>L3 -&gt; L2 = M*(N/n_c)*K + M*(N/n_c)*(K/k_c) + (M/m_c)*N*K + 2*M*N*(K/k_c) A x B C</p><ul>
<li>I*(N/n_c)*J + I*(N/n_c)*(J/j_c) + (I/i_c)*N*J + 2*I*N*(J/j_c) D y C E</li>
<li>2*M*K + 2*N*K + 2*I*J + 2*N*J pA pB pD pC Held: k_c, m_c, n_r, order n_c, [k_c, m_c, n_r], m_r, k_r Held: j_c, i_c, n_r, order n_c, [j_c, i_c, n_r], i_r, j_r We would have the denominators <code>k_c</code>, <code>m_c</code>, <code>j_c</code>, <code>i_c</code>, and <code>n_r</code>, but because <code>n_r</code> is the inner-most of these, those that don't depend on it are hoisted out and have <code>n_c</code> instead.</li>
</ul>
<p>We have only <code>n_r</code> reg, making it the inner-most.</p>
<p>A: (M/m_c)(N/n_c)(K/k_c) * m_c*k_c x: (M/m_c)(N/n_c)(K/k_c) * m_c B: (M/m_c)(N/n_c)(K/k_c) * (n_c/n_r) * k_c*n_r</p>
<p>C: (N/n_c)*(n_c/n_r)*n_r*[2(M/m_c)(K/k_c)*m_c + (I/i_c)(J/j_c)*j_c] D: (I/i_c)(N/n_c)(J/j_r) * i_c*j_c y: (I/i_c)(N/n_c)(J/j_c) * i_c E: 2*(I/i_c)(N/n_c)(J/j_c) * (n_c/n_r) * i_c*n_r</p>
<p>RAM -&gt; L3 = M*(N/n_c)*K + M*(N/n_c)*(K/k_c) + N*K + 2*M*N*(K/k_c) A x B C</p><ul>
<li>I*(N/n_c)*J + I*(N/n_c)*(J/j_c) + N*J + 2*I*N*(J/j_c) D y C E</li>
<li>2*M*K + 2*N*K + 2*I*J + 2*N*J pA pB pD pC Held: n_c, k_c, m_c, order [n_c, k_c, m_c], n_r, m_r, k_r Held: n_c, j_c, i_c, order [n_c, j_c, i_c], n_r, i_r, j_r Because <code>m_c</code> and <code>i_c</code> are inner-most, we can hoist out: A: (M/m_c)(N/n_c)(K/k_c) * m_c*k_c x: (M/m_c)(N/n_c)(K/k_c) * m_c B: (N/n_c)(K/k_c) * k_c*n_c</li>
</ul>
<p>C: (N/n_c)*n_c*[2(M/m_c)(K/k_c)*m_c + (J/j_c)*j_c] D: (I/i_c)(N/n_c)(J/j_r) * i_c*j_c y: (I/i_c)(N/n_c)(J/j_c) * i_c E: 2*(I/i_c)(N/n_c)(J/j_c) * i_c*n_c</p>
<p>We have the following contraints: We assume LRU (least-recently-used) cache.</p>
<p>Hold in L2: m_c*k_c &lt;= S_2*u_A2 k_c*n_r &lt;= S_2*u_B2 m_c*n_r &lt;= S_2*u_C2_0 m_c &lt;= S_2*u_X2 // u_X2 is probably 1 W_2 &gt;= u_A2 + 2*u_B2 + u_C2_0 + u_X2 i_c*j_c &lt;= S_2*u_D2 j_c*n_r &lt;= S_2*u_C2_1 i_c*n_r &lt;= S_2*u_E2 i_c &lt;= S_2*u_Y2 // u_Y2 is probably 1 W_2 &gt;= u_D2 + 2*u_C2_1 + u_E2 + u_Y2</p>
<p>The <code>2*</code> comes because it depends on <code>n_r</code> Order: n_c, [k_c, m_c, n_r], m_r, k_r A: 1 1 1 1 B: 1 1 1 1 C: 1 1 1 1 <code>k_r</code>, <code>m_r</code>, <code>n_r</code> make the <code>k_c</code>, <code>m_c</code>, <code>n_c</code> slices. When iterating <code>n_r</code>, <code>B[k_c,n_r]</code> and <code>C[m_c,n_r]</code> get replaced. We just iterated over last <code>m_r*k_c</code> tile. Therefore, last touched is all of <code>B[k_c,n_r]</code> but only last <code>C[m_r,n_r]</code>. Thus, incoming <code>C[m_r,n_r]</code> can replace old, which has not been touched for longer.</p>
<p>Perhaps another way to view it is, we only hold a <code>m_r*n_r</code> block of <code>C</code>, but based on use-pattern, we need <code>m_c/m_r</code> of them? Implement whichever is the easier representation, but that is probably the former.</p>
<p>Basically, when we replace <code>n_r</code>, we look at our last <code>m_r</code> to say what we touched most recently, and thus how much space we need. <code>m_r</code> was most recent, meaning we last touched <code>A[m_r, k_c]</code>, <code>C[m_r, n_r]</code>, and <code>B[k_c, n_r]</code> <code>B</code> was touched in entirety, so we need a copy.</p>
<p>Simplifying, we have: W_2 &gt;= (m_c*k_c)/S_2 + 2*((k_c*n_r)/S_2) + (m_c*n_r)/S_2 + m_c/S_2 W_2 &gt;= (i_c*j_c)/S_2 + 2*((j_c*n_r)/S_2) + (i_c*n_r)/S_2 + i_c/S_2</p>
<p>Hold in L3: m_c*k_c &lt;= S_3*u_A3 k_c*n_c &lt;= S_3*u_B3 m_c*n_c &lt;= S_3*u_C3_0 m_c &lt;= S_3*u_X3 // u_X3 is probably 1 W_3 &gt;= 2*u_A3 + u_B3 + u_C3_0 + u_X3 i_c*j_c &lt;= S_3*u_D3 j_c*n_c &lt;= S_3*u_C3_1 i_c*n_c &lt;= S_3*u_E3 i_c &lt;= S_3*u_Y3 // u_Y3 is probably 1 W_3 &gt;= 2*u_D3 + u_C3_1 + u_E3 + u_Y3</p>
<p>Order: [n_c, k_c, m_c], n_r, m_r, k_r A: 1 1 1 1 B: 1 1 1 1 C: 1 1 1 1</p>
<p>When we replace <code>m_c</code>, we swap out both <code>A[m_c, k_c]</code> and <code>C[m_c, n_c]</code>. <code>n_r</code> was the most recent, meaning we last touched: <code>A[m_c, k_c]</code>, <code>C[m_c, n_r]</code>, and <code>B[k_c, n_r]</code> <code>A</code> was touched in entirety, so we need a copy.</p>
<p>W_3 &gt;= 2*((m_c*k_c)/S_3) + (k_c*n_c)/S_3 + (m_c*n_c)/S_3 + m_c/S_3 W_3 &gt;= 2*((i_c*j_c)/S_3) + (j_c*n_c)/S_3 + (i_c*n_c)/S_3 + i_c/S_3</p>
<p>So here we have 5 unnkowns: m_c, k_c, i_c, j_c, n_c And four equations: W_2 &gt;= (m_c*k_c)/S_2 + 2*((k_c*n_r)/S_2) + (m_c*n_r)/S_2 + m_c/S_2 W_3 &gt;= 2*((m_c*k_c)/S_3) + (k_c*n_c)/S_3 + (m_c*n_c)/S_3 + m_c/S_3 W_2 &gt;= (i_c*j_c)/S_2 + 2*((j_c*n_r)/S_2) + (i_c*n_r)/S_2 + i_c/S_2 W_3 &gt;= 2*((i_c*j_c)/S_3) + (j_c*n_c)/S_3 + (i_c*n_c)/S_3 + i_c/S_3</p>
<p>Can we just pick a value, and propogate through? E.g., iterate over for (int m_c = m_r; m_c &lt; M; m_c += m_r){ Solve for k_c in: W_2 &gt;= (m_c*k_c)/S_2 + 2*((k_c*n_r)/S_2) + (m_c*n_r)/S_2 + m_c/S_2 W_2 - (m_c*n_r)/S_2 - m_c/S_2 &gt;= (m_c*k_c)/S_2 + 2*((k_c*n_r)/S_2) Now, how do we solve through <code>cld</code>? Using <code>W_2 = 16</code>, <code>m_c = 160</code>, <code>n_r = 14</code>, <code>S_2 = 8192</code> 14 &gt;= (160*k_c)/8192 + 2*((14*k_c)/8192) Every 8192/160 = 51.2, first cld increments Every 8192/14 \approx 585.14, second cld increments twice Thus, 585 yields... 16 - 1 - 1 == 12 + 2 While 586 exceeds, with 16 - 1 - 1 &lt; 12 + 4. Just take the lazy approach for now, and take steps... Next: W_3 &gt;= 2*((m_c*k_c)/S_3) + (k_c*n_c)/S_3 + (m_c*n_c)/S_3 + m_c/S_3 11 &gt;= 2*((160*585)/131072) + (585*n_c)/131072 + (160*n_c)/131072 + 160/131072 11 &gt;= 2 + (585*n_c)/131072 + (160*n_c)/131072 + 1 8 &gt;= (585*n_c)/131072 + (160*n_c)/131072 Ratios: S_3 / k_c \approx 224.05; S_3 / m_c == 819.2 We get n_C via 6*224 + 2 == 8 then cloest multiple of <code>n_r</code> (14) that is &lt;=, yielding: n_c = 1344 Next, we have W_2 &gt;= (i_c*j_c)/S_2 + 2*((j_c*n_r)/S_2) + (i_c*n_r)/S_2 + i_c/S_2 W_3 &gt;= 2*((i_c*j_c)/S_3) + (j_c*n_c)/S_3 + (i_c*n_c)/S_3 + i_c/S_3 16 &gt;= (i_c*j_c)/8192 + 2*((j_c*14)/8192) + (i_c*14)/8192 + i_c/8192 11 &gt;= 2*((i_c*j_c)/131072) + (j_c*1344)/131072 + (i_c*1344)/131072 + i_c/131072 What to do? Solve numerically, with floating point, and then? What happens if we init with bad values? }</p>
<p>One idea is to do a "bisection" on values of <code>n_f</code>, and then recursively descend into sub-loops in a similar manner. Once we've solved for others, we increase <code>n_c</code> to the largest value that satisfies the constraints, and measure full cost.</p>
<p>iterate 1k, 2k, then... if 1024 cost &lt; 2048 cost 512 if 1024 cost &gt; 2048 cost 4096 (but values rounded to multiple of nearest <code>x_r</code>)</p>
<p>Question: what do we do about different strategies? Can we smartly anchor the bisection around different thresholds?</p>
<p>e.g., n_c = 1022 W_1 &gt;= (m_r*k_c)/S_1 + (k_c*n_r)/S_1 + (m_r*n_r)/S_1 + m_r/S_1 W_2 &gt;= (m_c*k_c)/S_2 + 2*((k_c*n_r)/S_2) + (m_c*n_r)/S_2 + m_c/S_2 W_3 &gt;= 2*((m_c*k_c)/S_3) + (k_c*n_c)/S_3 + (m_c*n_c)/S_3 + m_c/S_3 8 &gt;= (16*k_c)/512 + (k_c*14)/512 + (16*14)/512 + 16/512 16 &gt;= (m_c*k_c)/8192 + 2*((k_c*14)/8192) + (m_c*14)/8192 + m_c/8192 11 &gt;= 2*((m_c*k_c)/131072) + (k_c*1022)/131072 + (m_c*1022)/131072 + m_c/131072 m_c = 512 k_c = 256 k_c = 128 k_c = 192 m_c = 256 m_c = 128 Start working on this implementation; we'll have all the constraints and associated costs and the search will be aware of them, ensuring it has explored both sides...</p>
<p>Another sort of example to consider is </p><pre class="fragment">for (int n = 0; n &lt; N; ++n){
  for (int m = 0; m &lt; M; ++m){
    Cmn = 0f0;
    for (int k = 0; k &lt; K; ++k)
      Cmn += A[m,k]*B[k,n];
    C[m,n] = f(Cmn + x[m]);
    Fmn = 0f0;
    for (int l = 0; l &lt; L; ++l)
      Fmn += D[m,l]*E[l,n];
    F[m,n] = g(Fmn + y[m]);
  }
}
</pre><p> How do we handle cache across subloops? A problem is replacement: First inner most loop wants m_r*n_r + m_r*k_c + k_c*n_r Second: m_r*n_r + m_r*l_c + l_c*n_r This loop is of course outright worse than splitting... But what if, e.g. <code>A == D</code>? Then, we'd have re-use of the tile could would be similar to incrementing <code>n_r</code> once, i.e. reuse <code>A</code> but need to load the other two. What to do? If <code>A != D</code>, we should have a way to check splitting profitability, or even heuristically assume it is. If <code>A == D</code>, perhaps still consider it? How to measure cost? Have dependent loops, that don't necessarilly match loop nestings. Above example: n -&gt; m -&gt; k == l May also have n -&gt; m -&gt; k -&gt; l First example n -&gt; m -&gt; k -&gt; i -&gt; j</p>
<p>We build traversal-trees based on constraints Except, then costs get more complicated? E.g., if we have n -&gt; m -&gt; k -&gt; l Then correspondence of these to trip or total traversal counts is less clear. Dep flags vs branching values... Could be replaced with dep vectors and indep vectors. For now, we'll solve heuristically, by choosing the larget of the unknown trip counts and matching tile sizes, so that the costs are the same. I.e., we'll always use n -&gt; m -&gt; k == l We use <code>lcm(k_r, l_r)</code> for purpose of cache-factor</p>
<p>If nothing in common, for split. If something in common, test matching dependent loops/equal tile size TODO: splitting is NOT trivial. Check for weakly connected components? Width of connections between loops that need to be stored/reloaded? How to find the narrowest point?</p>
<h2><a class="anchor" id="autotoc_md0"></a>
Have load and store cost for split. Splits should also handle</h2>
<div class="fragment"><div class="line"><span class="keywordflow">for</span> (<span class="keywordtype">int</span> n = 0; n &lt; N; ++n){</div>
<div class="line">  <span class="keywordflow">for</span> (<span class="keywordtype">int</span> m = 0; m &lt; M; ++m){</div>
<div class="line">    Cmn = 0f0;</div>
<div class="line">    Dmn = 0f0;</div>
<div class="line">    <span class="keywordflow">for</span> (<span class="keywordtype">int</span> k = 0; k &lt; K; ++k){</div>
<div class="line">      Cmn += A[m,k]*B[k,n];</div>
<div class="line">      Dmn += A[m,k]*E[k,n];</div>
<div class="line">    }</div>
<div class="line">    C[m,n] = f(Cmn + x[m]);</div>
<div class="line">    D[m,n] = g(Dmn + y[m]);</div>
<div class="line">  }</div>
<div class="line">}</div>
</div><!-- fragment --><p> These can infuence register tiling decisions, and thus should not be handled downstream of register tiling. Ideally, before redundant load elimination?</p>
<p>clang-format on</p>
<p>Let us consider how to correctly handle multiple sub-loops. For now, we will take the approach of "dumping" contents, i.e. assuming each subloop wants to use the full cache. This can be viewed as approximating a loop over the subloops, but where each loop iteration does something different (i.e. evaluate a different subloop).</p>
<p>Any tile not indexed by a sub-loop or deeper contributes to the cache-fit of all sub-loops, but to the fit-cost of only one of them.</p>
<p>Our buffer can store arrays sorted by indices; makes dropping as we exit a loop natural.</p>
<p>Any tile indexed by a subloop or descendent is evicted, unless it is used by the next &ndash; and the next has a matching tile size. If ever evicted (e.g., not used by all), it would need to be reloaded.</p>
<p>For handling sub-loops of <code>i</code>, there are two possibilities:</p><ol type="1">
<li>Fuse &amp; nest: We fuse just the <code>+= i_c</code> loops.</li>
<li>Fuse &amp; fuse: We fuse the <code>+= i_c</code> and <code>+= i_r</code> loops.</li>
</ol>
<h3><a class="anchor" id="autotoc_md1"></a>
Fuse &amp; nest:</h3>
<p>The significance of the latter is that it requires also fusing the sub-loop tile sizes. Implications of the former are that we can and must share tiles indexed only by the common loops <code>i</code> and those exterior to <code>i</code>, but we can solve interior loops indepdently. They will fully iterate inside, so we do not have special considerations there. This also makes dependencies less of a concern, so long as <code>i</code> doesn't carry any. When taking this approach, the subloops are marked as effectively always changing.</p>
<p>clang-format off </p><pre class="fragment">for (int i = 0; i &lt; I; ++i){
  for (int j0 = 0; j0 &lt; J0; ++j0){ A[i,j0]; B[j0]; C[i]; }
  for (int j1 = 0; j1 &lt; J1; ++j1){ D[i,j1]; E[j1]; F[i]; }
  for (int j2 = 0; j2 &lt; J2; ++j2){ G[i,j2]; H[j2]; X[i]; }
}
</pre><p> This can turn into </p><pre class="fragment">for (int i_c_b = 0; ic_b &lt; I; i_c_b += i_c){
  // change: C[i_c_b+_(0,i_c)];
  for (int j0_c_b = 0; j0_c_b &lt; J0; j0_c_b += j0_c){
    // change: B[j0_c_b+_(0,j0_c)];
    // const:  C[i_c_b+_(0,i_c)];
    for (int i_r_b = i_c_b; i_r_b &lt; i_c_b+i_c; i_c_b += i_c){
      // const:  B[j0_c_b+_(0,j0_c)];
      // change: C[i_r_b+_(0,i_r)];
      for (int j0_r_b = j0_c_b; j0_r_b &lt; j0_c_b+j0_c; j0_c_b += j0_r){
        // change: A[i_r_b+_(0,i_r), j0_r_b+_(0,j0_r)];
        // change: B[j0_r_b+_(0,j0_r)];
        // const:  C[i_r_b+_(0,i_r)];
      }
    }
  }
  for (int j1_c_b = 0; j1_c_b &lt; J1; j1_c_b += j1_c){
    for (int i_r_b = i_c_b; i_r_b &lt; i_c_b+i_c; i_c_b += i_c){
      for (int j1_r_b = j1_c_b; j1_r_b &lt; j1_c_b+j1_c; j1_c_b += j1_r){
        A[i_r_b+_(0,i_r), j1_r_b+_(0,j1_r)];
        B[j1_r_b+_(0,j1_r)];
        C[i_r_b+_(0,i_r)];
      }
    }
  }
  for (int j2_c_b = 0; j2_c_b &lt; J2; j2_c_b += j2_c){
    for (int i_r_b = i_c_b; i_r_b &lt; i_c_b+i_c; i_c_b += i_c){
      for (int j2_r_b = j2_c_b; j2_r_b &lt; j2_c_b+j2_c; j2_c_b += j2_r){
        A[i_r_b+_(0,i_r), j2_r_b+_(0,j2_r)];
        B[j2_r_b+_(0,j2_r)];
        C[i_r_b+_(0,i_r)];
      }
    }
  }
}
</pre><p> clang-format on</p>
<p>All we must do is avoid the optimization of reversing <code>j*_c_b</code>, as we can't hold anyway.</p>
<h3><a class="anchor" id="autotoc_md2"></a>
Fuse &amp; fuse:</h3>
<p>This involves interleaving the subloops, and lock their cache tile sizes. This allows reuse between subloops, but requires they not carry dependencies either. We do not necessarilly need to fuse all, e.g. we could fuse only the first subloop, and then take a nesting approach from there. TODO: implement this as an option to consider; it is likely to yield better perf in some circumstances. </p>
</div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a262108c303cebcad7d025f8156f1b8d7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a262108c303cebcad7d025f8156f1b8d7">&#9670;&nbsp;</a></span>fillTileSizes()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static void CostModeling::Cache::CacheOptimizer::fillTileSizes </td>
          <td>(</td>
          <td class="paramtype">MutStridedVector&lt; int &gt;&#160;</td>
          <td class="paramname"><em>tile_size</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const TinyVector&lt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Loop.html">Loop</a>, 15 &gt; &amp;&#160;</td>
          <td class="paramname"><em>unrolls</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint16_t&#160;</td>
          <td class="paramname"><em>deps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>cpy_mask</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ptrdiff_t&#160;</td>
          <td class="paramname"><em>depth0</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int&#160;</td>
          <td class="paramname"><em>size</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>fill cache fits with sizes (product of cache tile sizes) and the <code>fit_coef</code>. </p>

</div>
</div>
<a id="a9ad521a4a3719807937f071802a1fbf8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9ad521a4a3719807937f071802a1fbf8">&#9670;&nbsp;</a></span>fitGrid()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">auto CostModeling::Cache::CacheOptimizer::fitGrid </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> &amp;&#160;</td>
          <td class="paramname"><em>deps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1InnerMostConstraint.html">InnerMostConstraint</a>&#160;</td>
          <td class="paramname"><em>imc</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> -&gt; DensePtrMatrix&lt;int&gt; </td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>Each row corresponds to a cache level Each column corresponds to some tiling behavior. The values are the maximum inner-most tile factor that will fit.</p>
<p>Within a row, the values should be decreasing, i.e. each successive tiling strategy requires a smaller tile factor. Each tiling strategy is ordered from highest to lowest cost, given equal tile factors.</p>
<p>The trade off is high cost corresponds with larget tile factors, low cost requires small tile factors.</p>
<p>Tiling strategies are: 1 strided tile (optional) 1 tile without striding (optional) 2 tiles 3 tiles ... depth1 tiles</p>
<p>We must have at least one of the 1-tile strategies. </p>

</div>
</div>
<a id="a080b9bac825d2eec5cf8d48be3ea8caa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a080b9bac825d2eec5cf8d48be3ea8caa">&#9670;&nbsp;</a></span>optInnerMost()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">auto CostModeling::Cache::CacheOptimizer::optInnerMost </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1DepSummary.html">DepSummary</a> *&#160;</td>
          <td class="paramname"><em>deps_ptr</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">ptrdiff_t&#160;</td>
          <td class="paramname"><em>chain_len</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> -&gt; <a class="el" href="structCostModeling_1_1Cache_1_1CacheOptimizer_1_1Best.html">Best</a> </td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">deps</td><td><code>Tuple</code> consists of <code>deps</code>, <code>fit_coef</code>, and <code>cost_coef</code>. <code>fit_coef</code> is used for determining whether arrays fit, while <code>cost_coef</code> is for bandwidth costs. These two may not be equal, e.g. if we both load and store from an array, it contributes once to <code>fit_coef</code> but twice to <code>cost_coef</code>. Returns: double: best cost int: best cache factor for the inner-most loop int: best choice for the inner-most cache loop, offset by <code>1</code>. </td></tr>
  </table>
  </dd>
</dl>

</div>
</div>
<a id="a9dc132ec0ec903fba009f6e3c8a28811"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9dc132ec0ec903fba009f6e3c8a28811">&#9670;&nbsp;</a></span>rotateDepMask()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">static constexpr auto CostModeling::Cache::CacheOptimizer::rotateDepMask </td>
          <td>(</td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>deps</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>reg</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">uint32_t&#160;</td>
          <td class="paramname"><em>cache</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td> -&gt; uint32_t </td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel">inline</span><span class="mlabel">static</span><span class="mlabel">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">
<p>deps go <code>outer-&gt;inner</code> for a bitfield, that means outer occupies the right-most bits [0-padding..., inner, ..., outer] This produces an updated-dep-mask for the purpose of cache-optimization. outer-&gt;inner: [ n, m, k] reg = 1, i.e. reg = [n], returns [m_c, k_c, n_r] reg = 2, i.e. reg = [n, m], returns [k_c, n_r, m_r] </p>

</div>
</div>
<hr/>The documentation for this struct was generated from the following file:<ul>
<li>mod/Optimize/CacheOptimization.cxx</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.9.1
</small></address>
</body>
</html>
